# NOTE: crowding-distance uses user-provided fixed bounds normalization (use --fixed-ref-bounds f1_min f1_max f2_min f2_max)

#!/usr/bin/env python3
"""NSGA-II for ZDT3 (NSGA-II standard)
Auto-generated script following course slides and report spec.
Run: python3 nsga2_zdt3.py --pop 100 --gen 250 --runs 10

Outputs:
- prints final Pareto front to stdout (first 20 points)
- computes Hypervolume and Spacing

This implementation uses:
- tournament selection (size 2)
- BLX-alpha (blend) crossover for real/integer - results are rounded for integers
- Random Resetting mutation for integer ZDT1
- Uniform mutation for real ZDT3

Author: generated by ChatGPT (assistant)
"""

import argparse
import random
import math
import csv
from copy import deepcopy

random.seed(0)

# ---------- Problem-specific functions ----------

def zdt1(x):
    # x: list of integers in [0,1000]
    n = len(x)
    x_real = [xi / 1000.0 for xi in x]  # normalization internal
    f1 = x_real[0]
    g = 1.0 + 9.0 * sum(x_real[1:]) / (n - 1)
    h = 1.0 - math.sqrt(f1 / g)
    f2 = g * h
    return (f1, f2)

def zdt3(x):
    # x: list of reals in [0,1]
    n = len(x)
    f1 = x[0]
    g = 1.0 + 9.0 * sum(x[1:]) / (n - 1)
    h = 1.0 - math.sqrt(f1 / g) - (f1 / g) * math.sin(10 * math.pi * f1)
    f2 = g * h
    return (f1, f2)

# ---------- Utilities: Non-dominated sort, crowding distance ----------

def dominates(a, b):
    # a and b are tuples (f1,f2); minimize both
    return (a[0] <= b[0] and a[1] <= b[1]) and (a[0] < b[0] or a[1] < b[1])

def non_dominated_sort(pop_objs):
    # pop_objs: list of tuples (objectives), returns fronts as lists of indices
    S = [set() for _ in pop_objs]
    n = [0 for _ in pop_objs]
    fronts = [[]]
    for p in range(len(pop_objs)):
        for q in range(len(pop_objs)):
            if dominates(pop_objs[p], pop_objs[q]):
                S[p].add(q)
            elif dominates(pop_objs[q], pop_objs[p]):
                n[p] += 1
        if n[p] == 0:
            fronts[0].append(p)
    i = 0
    while fronts[i]:
        next_front = []
        for p in fronts[i]:
            for q in list(S[p]):
                n[q] -= 1
                if n[q] == 0:
                    next_front.append(q)
        i += 1
        fronts.append(next_front)
    fronts.pop()  # last empty
    return fronts

def crowding_distance(pop_objs, front, fixed_bounds=None):
    # fixed_bounds: ((f1_min,f1_max),(f2_min,f2_max)) used to normalize when provided
    distances = {i:0.0 for i in front}
    if not front:
        return distances
    # for each objective
    for m in range(2):
        values = [(pop_objs[i][m], i) for i in front]
        values.sort(key=lambda x:x[0])
        minv = values[0][0]
        maxv = values[-1][0]
        if fixed_bounds is not None:
            if m == 0:
                minv, maxv = fixed_bounds[0]
            else:
                minv, maxv = fixed_bounds[1]
        # boundary points get infinite distance
        distances[values[0][1]] = float('inf')
        distances[values[-1][1]] = float('inf')
        denom = maxv - minv
        if denom == 0:
            continue
        for k in range(1, len(values)-1):
            prevv = values[k-1][0]
            nextv = values[k+1][0]
            distances[values[k][1]] += (nextv - prevv) / denom
    return distances

# ---------- Selection and genetic operators ----------

def tournament_selection(pop, pop_objs, k=2):
    i1 = random.randrange(len(pop))
    i2 = random.randrange(len(pop))
    if dominates(pop_objs[i1], pop_objs[i2]):
        return deepcopy(pop[i1])
    elif dominates(pop_objs[i2], pop_objs[i1]):
        return deepcopy(pop[i2])
    else:
        return deepcopy(pop[random.choice([i1,i2])])

def blend_crossover(parent1, parent2, alpha=0.5, is_integer=False):
    # BLX-alpha generalized for lists
    child1 = []
    child2 = []
    for a, b in zip(parent1, parent2):
        low = min(a,b) - alpha * abs(b - a)
        high = max(a,b) + alpha * abs(b - a)
        val1 = random.uniform(low, high)
        val2 = random.uniform(low, high)
        if is_integer:
            child1.append(int(round(min(max(val1, 0), 1000))))
            child2.append(int(round(min(max(val2, 0), 1000))))
        else:
            child1.append(min(max(val1, 0.0), 1.0))
            child2.append(min(max(val2, 0.0), 1.0))
    return child1, child2

def mutation_integer_random_reset(individual, p_mut=0.01):
    for i in range(len(individual)):
        if random.random() < p_mut:
            individual[i] = random.randint(0,1000)

def mutation_real_uniform(individual, p_mut=0.01):
    for i in range(len(individual)):
        if random.random() < p_mut:
            individual[i] = random.random()

# ---------- Metrics: Hypervolume and Spacing ----------

def hypervolume(front, ref_point):
    # front: list of (f1,f2) minimized. ref_point is (r1,r2) worse-than-worst
    pts = sorted(front, key=lambda x: x[0])
    hv = 0.0
    pts_rev = sorted(front, key=lambda x:x[0], reverse=True)
    last_f1 = ref_point[0]
    for f1,f2 in pts_rev:
        width = last_f1 - f1
        if width > 0:
            height = ref_point[1] - f2
            hv += width * max(height, 0.0)
            last_f1 = f1
    return hv

def spacing(front):
    # as defined in slides: measure distribution uniformity on the front
    if len(front) <= 1:
        return 0.0
    d = []
    for i in range(len(front)):
        di = []
        for j in range(len(front)):
            if i==j: continue
            dist = sum(abs(front[i][k] - front[j][k]) for k in range(2))
            di.append(dist)
        d.append(min(di))
    mean_d = sum(d)/len(d)
    var = sum((di - mean_d)**2 for di in d) / (len(d)-1) if len(d)>1 else 0.0
    return math.sqrt(var)

# ---------- Main evolutionary loop (NSGA-II) ----------

def nsga2(problem='zdt1', pop_size=100, n_var=50, generations=250,
          p_crossover=0.9, p_mut=0.1, alpha=0.5, fixed_bounds=None, no_crowding=False,
          ref_point=None, track_convergence=False):
    # initialize population
    is_integer = (problem=='zdt1')
    pop = []
    for _ in range(pop_size):
        if is_integer:
            pop.append([random.randint(0,1000) for _ in range(n_var)])
        else:
            pop.append([random.random() for _ in range(n_var)])

    # evaluate
    def eval_pop(pop):
        objs = []
        for ind in pop:
            if problem=='zdt1':
                objs.append(zdt1(ind))
            else:
                objs.append(zdt3(ind))
        return objs

    pop_objs = eval_pop(pop)
    evals = pop_size
    
    # Track convergence metrics per generation
    convergence_data = {
        'generation': [],
        'hypervolume': [],
        'spacing': [],
        'pareto_size': []
    }

    for gen in range(generations):
        # create offspring
        offspring = []
        while len(offspring) < pop_size:
            parent1 = tournament_selection(pop, pop_objs)
            parent2 = tournament_selection(pop, pop_objs)
            if random.random() < p_crossover:
                child1, child2 = blend_crossover(parent1, parent2, alpha, is_integer=is_integer)
            else:
                child1, child2 = deepcopy(parent1), deepcopy(parent2)
            # mutation
            if is_integer:
                mutation_integer_random_reset(child1, p_mut)
                mutation_integer_random_reset(child2, p_mut)
            else:
                mutation_real_uniform(child1, p_mut)
                mutation_real_uniform(child2, p_mut)
            offspring.append(child1)
            if len(offspring) < pop_size:
                offspring.append(child2)
        # evaluate offspring
        off_objs = eval_pop(offspring)
        evals += pop_size
        # merge
        union = pop + offspring
        union_objs = pop_objs + off_objs
        fronts = non_dominated_sort(union_objs)
        new_pop = []
        new_objs = []
        for front in fronts:
            if len(new_pop) + len(front) <= pop_size:
                # include entire front
                for idx in front:
                    new_pop.append(union[idx])
                    new_objs.append(union_objs[idx])
            else:
                # need partial fill
                if no_crowding:
                    # choose randomly among this front to fill remaining slots
                    remaining = pop_size - len(new_pop)
                    chosen = random.sample(front, remaining)
                    for idx in chosen:
                        new_pop.append(union[idx])
                        new_objs.append(union_objs[idx])
                else:
                    # compute crowding distance (possibly with fixed bounds)
                    dist = crowding_distance(union_objs, front, fixed_bounds=fixed_bounds)
                    # sort by distance descending (infinite first)
                    sorted_front = sorted(front, key=lambda i: (dist[i] if dist[i] != float('inf') else 1e9), reverse=True)
                    remaining = pop_size - len(new_pop)
                    for idx in sorted_front[:remaining]:
                        new_pop.append(union[idx])
                        new_objs.append(union_objs[idx])
                break
        pop = new_pop
        pop_objs = new_objs
        
        # Track convergence metrics if requested
        if track_convergence and ref_point is not None:
            fronts_temp = non_dominated_sort(pop_objs)
            pareto_temp = [pop_objs[i] for i in fronts_temp[0]]
            if pareto_temp:
                hv_temp = hypervolume(pareto_temp, ref_point)
                sp_temp = spacing(pareto_temp)
                convergence_data['generation'].append(gen + 1)
                convergence_data['hypervolume'].append(hv_temp)
                convergence_data['spacing'].append(sp_temp)
                convergence_data['pareto_size'].append(len(pareto_temp))

    # final non-dominated front from last population
    fronts = non_dominated_sort(pop_objs)
    pareto_idx = fronts[0]
    pareto = [pop_objs[i] for i in pareto_idx]
    
    if track_convergence:
        return pareto, evals, convergence_data
    return pareto, evals

# ---------- CLI ----------

def parse_args():
    parser = argparse.ArgumentParser()
    parser.add_argument('--pop', type=int, default=100)
    parser.add_argument('--gen', type=int, default=250)
    parser.add_argument('--nvar', type=int, default=50)
    parser.add_argument('--runs', type=int, default=10)
    parser.add_argument('--ref', type=float, nargs=2, default=None, help='reference point for Hypervolume (r1 r2)')
    parser.add_argument('--no-crowd', action='store_true', help='run NSGA-II but when last front overflows select randomly')
    parser.add_argument('--fixed-ref-bounds', type=float, nargs=4, default=None,
                        help='For crowding distance normalization: provide fixed bounds f1_min f1_max f2_min f2_max (use for fixedref variant)')
    return parser.parse_args()

def main(problem, filename):
    args = parse_args()
    hv_list = []
    spacing_list = []
    for run in range(args.runs):
        fixed_bounds = None
        if args.fixed_ref_bounds:
            fixed_bounds = ((args.fixed_ref_bounds[0], args.fixed_ref_bounds[1]),
                            (args.fixed_ref_bounds[2], args.fixed_ref_bounds[3]))
        pareto, evals = nsga2(problem=problem, pop_size=args.pop, n_var=args.nvar,
                              generations=args.gen, p_crossover=0.9, p_mut=0.05,
                              alpha=0.5, fixed_bounds=fixed_bounds, no_crowding=args.no_crowd)
        if args.ref is None:
            # automatic ref point: slightly worse than max observed in pareto
            maxf1 = max(p[0] for p in pareto) if pareto else 1.0
            maxf2 = max(p[1] for p in pareto) if pareto else 1.0
            ref = (maxf1 * 1.2 + 1e-9, maxf2 * 1.2 + 1e-9)
        else:
            ref = (args.ref[0], args.ref[1])
        hv = hypervolume(pareto, ref)
        sp = spacing(pareto)
        hv_list.append(hv)
        spacing_list.append(sp)
        if run == 0:
            print(f'Run {run+1}: evaluations={evals} pareto_size={len(pareto)} ref={ref} hv={hv:.6g} spacing={sp:.6g}')
            for p in pareto[:20]:
                print(f'{p[0]:.6g}, {p[1]:.6g}')
    # summary statistics
    def stats(lst):
        return (min(lst), sum(lst)/len(lst), max(lst))
    print('\\nHV stats (min, mean, max):', stats(hv_list))
    print('Spacing stats (min, mean, max):', stats(spacing_list))

if __name__ == '__main__':
    import sys
    main(problem='zdt3', filename='nsga2_zdt3.py')
